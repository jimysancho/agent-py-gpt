{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`What is a subject?` $\\implies$ Any Python function, method, class or block of code. \n",
    "\n",
    "We need to create the Agent that will decide the tool to use based on a query. There will be two agents: \n",
    "1. **Simple vs Complex Agent**. This agent will classify the query of the user into one of these categories: \n",
    "\n",
    "- Simple:  Zero or nne subject present in the question. *Example: How does the function x work?*\n",
    "- Complex: More than one subject.  *Example: What are the differences between Class A and Class B?*\n",
    "\n",
    "- Tool returned: **`SimpleRetriever`**\n",
    "\n",
    "\n",
    "2. **General vs Particular Agent**. This agent will the output from the first agent only if the question type was: **`Simple`** and classify the question into one of two categories: \n",
    "\n",
    "- Particular: The question involves only the subject. *Example: How does the function x work?*\n",
    "- General: The question is formulated in such a way that the question does not have to do only with the subject. *Will my changes break anything?*\n",
    "\n",
    "- Tool returned: **`SimpleRetriever`** or **`GeneralRetriever`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from app.agent.multi_agent import MultiAgent\n",
    "from app.agent.agent import ContextTypeAgent, QuestionTypeAgent\n",
    "from app.prompts.prompts import SIMPLE_VS_COMPLEX, GENERAL_VS_PARTICULAR_CONTEXT\n",
    "from app.prompts.prompt import Prompt\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# simple vs complex -> 0-1 vs > 1 subjects\n",
    "simple_vs_complex_prompt = Prompt(prompt=SIMPLE_VS_COMPLEX)\n",
    "simple_vs_complex_agent = QuestionTypeAgent(\n",
    "    instruction=simple_vs_complex_prompt\n",
    ")\n",
    "\n",
    "# general vs particular\n",
    "general_vs_particular_prompt = Prompt(GENERAL_VS_PARTICULAR_CONTEXT)\n",
    "general_vs_particular_agent = ContextTypeAgent(\n",
    "    instruction=general_vs_particular_prompt\n",
    "    )\n",
    "\n",
    "multi_agent = MultiAgent(agents=[\n",
    "    simple_vs_complex_agent, \n",
    "    general_vs_particular_agent\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Classification Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We are going to test how the agent classify the questions and what tools does it choose to answer the question**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.database.base import get_db\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "db = next(get_db())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.retrievers.general_retriever import GeneralRetriever\n",
    "from app.retrievers.similarity_retriever import SimilarityRetriever\n",
    "\n",
    "\n",
    "async def tool_pipeline(agent: MultiAgent, query: str, db: Session=db):\n",
    "    tool, output = await agent.pipeline(query=query)\n",
    "    tool: GeneralRetriever | SimilarityRetriever = tool(db=db)\n",
    "    return tool.query_database(query=query, subjects=output.subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 General question retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This one is a tricky one because we are specifying a line of code besides the function. That is not an issue because of how our retrievers are built. We'll look to see if can find the subject based on the function name, method name or class name fields of the NodeMetadata.node_metadata column. That is why Postgres is so powerfull!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subject is the function _create_node_relationships_file therefore the answer is simple because there is only one subject\u001b[0m\n",
      "\u001b[34mAgent answer: simple \n",
      "\u001b[0m\n",
      "\u001b[34mAgent reasoning response: The question refers to what will happen when removing a line from the function, which is not about the subject itself, but about its effects, therefore the answer is general\u001b[0m\n",
      "\u001b[34mAgent answer: general \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: GeneralRetriever\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\tExact match of subject: {'_create_node_relationships_file'} in the database. --> 1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"What will happen If I remove the line 'os.remove(name_file)' of the function _create_node_relationships_file\"\n",
    "nodes, nodes_with_score = asyncio.run(tool_pipeline(agent=multi_agent, query=query, db=db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def _create_node_relationships_file(db: Session):\n",
      "    \n",
      "    fields = ('class_name', 'function_name', 'method_name')\n",
      "    name_file = os.environ['NAMES_FILE']\n",
      "    relationships_file = os.environ['RELATIONSHIPS_FILE']\n",
      "    \n",
      "    os.remove(name_file)\n",
      "    \n",
      "    if not os.path.exists(name_file):\n",
      "        nodes\n",
      "async def update_nodes_store(db: Session = Depends(get_db)):\n",
      "    updated_files = _create_file_node(path=os.environ['USER_CODE_DIRECTORY'], db=db)\n",
      "    _create_node_relationships_file(db=db)\n",
      "    return {\"py_files\": updated_files}\n",
      "\n",
      "async def upload_file_zip(file: UploadFile = File(...), db: Session = Depends(get_db)):\n",
      "\n",
      "    extract_dir = os.environ['USER_CODE_DIRECTORY']\n",
      "    if not os.path.exists(extract_dir):\n",
      "        # shutil.rmtree(extract_dir)\n",
      "        \n",
      "        os.makedirs(extract_dir, exist_ok=True)\n",
      "\n",
      "        with open(f\"{ext\n"
     ]
    }
   ],
   "source": [
    "# we print some of the nodes in which the function _create_node_relationships_file appears\n",
    "for node in nodes:\n",
    "    print(node.text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Particular Question retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's see one in which several retries have been needed to actually get a coherent answer: multiple subjects $\\implies$ complex question whereas one subject $\\implies$ simple.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subject is the class NodePostProccesor therefore the answer is complex because there is one class.\u001b[0m\n",
      "\u001b[34mAgent answer: complex \n",
      "\u001b[0m\n",
      "\u001b[31mNot valid answer. Applying retries\u001b[0m\n",
      "\u001b[31m\tRetry agent response: {\"question_type\": \"complex\", \"subject\": [\"NodePostProccesor\"], \"reasoning\": \"The subject is the class NodePostProccesor therefore the answer is complex because there is one subject\"}\u001b[0m\n",
      "\u001b[31m\tRetry agent response: {\"question_type\": \"complex\", \"subject\": [\"NodePostProccesor\"], \"reasoning\": \"The subject is the class NodePostProccesor therefore the answer is complex because there is only one subject, which is a class\"}\u001b[0m\n",
      "\u001b[31m\tRetry agent response: {\"question_type\": \"complex\", \"subject\": [\"NodePostProccesor\"], \"reasoning\": \"The subject is the class NodePostProccesor therefore the answer is complex because there is only one subject which is a class\"}\u001b[0m\n",
      "\u001b[31m\tRetry agent response: {\"question_type\": \"simple\", \"subject\": [\"NodePostProccesor\"], \"reasoning\": \"The subject is the class NodePostProccesor therefore the answer is simple because there is only one subject\"}\u001b[0m\n",
      "\u001b[34mAgent reasoning response: The question is regarding the implementation of the class NodePostProccesor itself, therefore the answer is particular\u001b[0m\n",
      "\u001b[34mAgent answer: particular \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: SimilarityRetriever\u001b[0m\n",
      "\u001b[34mOriginal Query: Explain to me how the class NodePostProccesor is implemented\u001b[0m\n",
      "\u001b[34m\tExact match of subject: NodePostProccesor in the database. --> 1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"Explain to me how the class NodePostProccesor is implemented\"\n",
    "nodes, _ = asyncio.run(tool_pipeline(agent=multi_agent, query=query, db=db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class NodePostProccesor:\n",
      "  \n",
      "    def __init__(self, retrieved_nodes_score: List[NodeWithScore], db: Session, score_threshold: float=0.8, min_parent_nodes: int=2, min_file_nodes: int=2):\n",
      "        \n",
      "        self._retrieved_nodes_score = [node for node in retrieved_nodes_score if node.score > score_thresh\n"
     ]
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    print(node.text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see, the output has modified the name of the subject: NodePostProcesor has changed to NodePostProcessor. This implies that we won't get a perfect match from the database, so similarity search will be performed. We still get the appropiate Node.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subject is NodePostProccesor class therefore the answer is complex because there is one subject.\u001b[0m\n",
      "\u001b[34mAgent answer: complex \n",
      "\u001b[0m\n",
      "\u001b[31mNot valid answer. Applying retries\u001b[0m\n",
      "\u001b[31m\tRetry agent response: {\"question_type\": \"simple\", \"subject\": [\"NodePostProcessor\"], \"reasoning\": \"The subject is NodePostProcessor, therefore the answer is simple because there is only one subject\"}\u001b[0m\n",
      "\u001b[34mAgent reasoning response: The question is regarding the implementation of NodePostProcessor itself, therefore the answer is particular\u001b[0m\n",
      "\u001b[34mAgent answer: particular \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: SimilarityRetriever\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mOriginal Query: Explain to me how NodePostProccesor is implemented\u001b[0m\n",
      "\u001b[34m\tNew query to look with subject: NodePostProcessor -->  explain to me how nodepostproccesor is implemented\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# let's try again with the same question but removing the word class\n",
    "# this time it gets a coherent answer faster\n",
    "query = \"Explain to me how NodePostProccesor is implemented\"\n",
    "nodes = asyncio.run(tool_pipeline(agent=multi_agent, query=query, db=db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class NodePostProccesor:\n",
      "  \n",
      "    def __init__(self, retrieved_nodes_score: List[NodeWithScore], db: Session, score_threshold: float=0.8, min_parent_nodes: int=2, min_file_nodes: int=2):\n",
      "        \n",
      "        self._retrieved_nodes_score = [node for node in retrieved_nodes_score if node.score > score_thresh\n"
     ]
    }
   ],
   "source": [
    "for node in nodes[0]:\n",
    "    print(node.text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Complex question retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we want our Agent to identify multiple subjects.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subjects are: _create_file_node function and _create_nodes_of_file function, therefore the answer is complex because there are more than one subject.\u001b[0m\n",
      "\u001b[34mAgent answer: complex \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: SimilarityRetriever\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mOriginal Query: How does the function _create_file_node depend on the function _create_nodes_of_file?\u001b[0m\n",
      "\u001b[34m\tExact match of subject: _create_file_node in the database. --> 1\u001b[0m\n",
      "\u001b[34m\tExact match of subject: _create_nodes_of_file in the database. --> 1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"How does the function _create_file_node depend on the function _create_nodes_of_file?\"\n",
    "nodes, _ = asyncio.run(tool_pipeline(agent=multi_agent, query=query, db=db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def _create_file_node(path: str, db: Session):\n",
      "    updated_files = []\n",
      "    for root, _, files in os.walk(path):\n",
      "        for file in files:\n",
      "            lines = open(os.path.join(root, file), \"r\").readlines()\n",
      "            text = \"\".join(lines)\n",
      "            hash = calculate_hash(text)\n",
      "            file = F\n",
      "def _create_nodes_of_file(path: str, db: Session, file_id: str):\n",
      "    files_structure_folder = os.environ['FILES_STRUCTURE_FOLDER']\n",
      "    os.makedirs(files_structure_folder, exist_ok=True)\n",
      "    \n",
      "    if path.startswith(\".\"): path = path[2:]\n",
      "    elif path.startswith(\"..\"): path = path[3:]\n",
      "    \n",
      "    file_na\n"
     ]
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    print(node.text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Question-Answer with agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that we've seen that our agent classify properly some questions, let's actually find an answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.agent.llama_client import LlamaClient\n",
    "from app.printer import Printer\n",
    "from app.prompts.prompts import PROMPT_TO_ANSWER_QUESTIONS\n",
    "\n",
    "printer = Printer()\n",
    "query = \"How does the function _create_file_node depend on the function _create_nodes_of_file?\"\n",
    "\n",
    "llm = LlamaClient()\n",
    "\n",
    "def format_answer(answer: str, max_words: int) -> str:\n",
    "    answer = answer.replace(\"\\n\\n\", \"\\n\")\n",
    "    lines = answer.split(\"\\n\")\n",
    "    processed_answer = \" \"\n",
    "    for line in lines:\n",
    "        words = line.split(\" \")\n",
    "        for k in range(0, len(words), max_words):\n",
    "            processed_line = \" \".join(words[k: k + max_words])\n",
    "            processed_answer += \"\\n\" + processed_line\n",
    "    return processed_answer\n",
    "\n",
    "async def query_pipeline(agent: MultiAgent, \n",
    "                         query: str, \n",
    "                         llm: LlamaClient, \n",
    "                         db: Session) -> str:\n",
    "    \n",
    "    tool, output = await agent.pipeline(query=query)\n",
    "    tool: GeneralRetriever | SimilarityRetriever = tool(db=db)\n",
    "    nodes, nodes_with_score, relationships = tool.query_database(query=query, subjects=output.subject)\n",
    "    for node_with_score in nodes_with_score:\n",
    "        printer.print_blue(f\"Score: {node_with_score.score} for text: \\n{node_with_score.node.text[:300]}\\n\")\n",
    "    if relationships: \n",
    "        for relation, relation_nodes in relationships.items():\n",
    "            for n, rel_node in enumerate(relation_nodes):\n",
    "                printer.print_blue(f\"\\tRelationship {n+1} for node --> {relation}: \\n{rel_node.text[:150]}\\n\")\n",
    "    context = \"\\n\".join([node.text for node in nodes])\n",
    "    prompt = Prompt.format_prompt(prompt=PROMPT_TO_ANSWER_QUESTIONS, context=context, query=query)\n",
    "    answer = await llm.acall(query=prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subjects are: _create_file_node function and _create_nodes_of_file function, therefore the answer is complex because there are more than one subject.\u001b[0m\n",
      "\u001b[34mAgent answer: complex \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: SimilarityRetriever\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mOriginal Query: How does the function _create_file_node depend on the function _create_nodes_of_file?\u001b[0m\n",
      "\u001b[34m\tExact match of subject: _create_nodes_of_file in the database. --> 1\u001b[0m\n",
      "\u001b[34m\tExact match of subject: _create_file_node in the database. --> 1\u001b[0m\n",
      "\u001b[34mScore: 1 for text: \n",
      "def _create_nodes_of_file(path: str, db: Session, file_id: str):\n",
      "    files_structure_folder = os.environ['FILES_STRUCTURE_FOLDER']\n",
      "    os.makedirs(files_structure_folder, exist_ok=True)\n",
      "    \n",
      "    if path.startswith(\".\"): path = path[2:]\n",
      "    elif path.startswith(\"..\"): path = path[3:]\n",
      "    \n",
      "    file_na\n",
      "\u001b[0m\n",
      "\u001b[34mScore: 1 for text: \n",
      "def _create_file_node(path: str, db: Session):\n",
      "    updated_files = []\n",
      "    for root, _, files in os.walk(path):\n",
      "        for file in files:\n",
      "            lines = open(os.path.join(root, file), \"r\").readlines()\n",
      "            text = \"\".join(lines)\n",
      "            hash = calculate_hash(text)\n",
      "            file = F\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "answer = asyncio.run(\n",
    "    query_pipeline(agent=multi_agent, \n",
    "                   query=query, \n",
    "                   llm=llm, \n",
    "                   db=db)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "The function `_create_file_node` depends on the function `_create_nodes_of_file` in that it calls this function internally.\n",
      "In particular, the line `db.add(file)` is followed by `_create_nodes_of_file(path=os.path.join(file.path), db=db, file_id=file.id)`, which suggests that once\n",
      "a new file node is created, all nodes of that file need to be processed\n",
      "and created using the `_create_nodes_of_file` function.\n",
      "Therefore, the order in which these two functions are called implies that `_create_nodes_of_file` is used\n",
      "to process the contents of each file.\n"
     ]
    }
   ],
   "source": [
    "formated_answer = format_answer(answer=answer, max_words=15)\n",
    "print(formated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subject is the __retrieve_relationship_nodes method, therefore the answer is simple since there is only one subject\u001b[0m\n",
      "\u001b[34mAgent answer: simple \n",
      "\u001b[0m\n",
      "\u001b[34mAgent reasoning response: The question involves the effect, which is different than the subject, therefore the answer is general.\u001b[0m\n",
      "\u001b[34mAgent answer: general \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: GeneralRetriever\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\tExact match of subject: {'__retrieve_relationship_nodes'} in the database. --> 1\u001b[0m\n",
      "\u001b[34mScore: 1 for text: \n",
      "    def __retrieve_relationship_nodes(self, base_id: str, node: Node, depth: int):\n",
      "        if base_id == str(node.id) or depth == 0: \n",
      "            return [node.id]\n",
      "        relations = []\n",
      "        node_relationships = node.node_relationships\n",
      "        if not node_relationships or not len(node_relationshi\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"If I change the parameter depth of the method: __retrieve_relationship_nodes what effect will that have?\"\n",
    "answer = asyncio.run(\n",
    "    query_pipeline(agent=multi_agent, \n",
    "                   query=query, \n",
    "                   llm=llm, \n",
    "                   db=db)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "A great question!\n",
      "The `depth` parameter in the `__retrieve_relationship_nodes` method controls how many levels of relationships are retrieved.\n",
      "Let's look at the code:\n",
      "```python\n",
      "def __retrieve_relationship_nodes(self, base_id: str, node: Node, depth: int):\n",
      "    ...\n",
      "    if depth == 0:\n",
      "        return [node.id]\n",
      "    ...\n",
      "    relations.extend(self.__retrieve_relationship_nodes(base_id=base_id, node=node_, depth=depth-1))\n",
      "```\n",
      "As you can see, the method calls itself recursively with a decreasing `depth` value until\n",
      "it reaches `depth == 0`. When `depth` is 0, it simply returns a list containing\n",
      "the ID of the current node.\n",
      "If you change the `depth` parameter, you'll affect how many levels of relationships are retrieved:\n",
      "* If `depth` is increased (e.g., from 2 to 3), more levels of relationships will\n",
      "be retrieved.\n",
      "* If `depth` is decreased (e.g., from 2 to 1), fewer levels of relationships will\n",
      "be retrieved.\n",
      "For example, if you call the method with `depth=2`, it will retrieve all relationships at\n",
      "level 1 and then recursively retrieve relationships at level 0 for each node at level\n",
      "1. If you call it with `depth=3`, it will also retrieve relationships at level 2\n",
      "for each node at level 1.\n",
      "So, changing the `depth` parameter controls the depth of the recursive relationship retrieval process.\n"
     ]
    }
   ],
   "source": [
    "formated_answer = format_answer(answer=answer, max_words=15)\n",
    "print(formated_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same question, but know another subject is involved to confuse the Agent. The *NodePostProccesor* class is the parent class of the method *__retrieve_relationships_nodes*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subjects are: NodePostProcessor class and __retrieve_relationship_nodes method, therefore the answer is complex because there are more than one subject.\u001b[0m\n",
      "\u001b[34mAgent answer: complex \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: SimilarityRetriever\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mOriginal Query: If I change the parameter depht of the method: __retrieve_relationship_nodes of the class NodePostProccesor what effect will that have?\u001b[0m\n",
      "\u001b[34m\tNew query to look with subject: NodePostProcessor -->  if i change the parameter depht of the method: __retrieve_relationship_nodes of the class nodepostproccesor what effect will that have?\u001b[0m\n",
      "\u001b[34m\tExact match of subject: __retrieve_relationship_nodes in the database. --> 1\u001b[0m\n",
      "\u001b[34mScore: 0.760384105455402 for text: \n",
      "class NodePostProccesor:\n",
      "  \n",
      "    def __init__(self, retrieved_nodes_score: List[NodeWithScore], db: Session, score_threshold: float=0.8, min_parent_nodes: int=2, min_file_nodes: int=2):\n",
      "        \n",
      "        self._retrieved_nodes_score = [node for node in retrieved_nodes_score if node.score > score_thresh\n",
      "\u001b[0m\n",
      "\u001b[34mScore: 1 for text: \n",
      "    def __retrieve_relationship_nodes(self, base_id: str, node: Node, depth: int):\n",
      "        if base_id == str(node.id) or depth == 0: \n",
      "            return [node.id]\n",
      "        relations = []\n",
      "        node_relationships = node.node_relationships\n",
      "        if not node_relationships or not len(node_relationshi\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"If I change the parameter depth of the method: __retrieve_relationship_nodes of the class NodePostProccesor what effect will that have?\"\n",
    "answer = asyncio.run(\n",
    "    query_pipeline(agent=multi_agent, \n",
    "                   query=query, \n",
    "                   llm=llm, \n",
    "                   db=db)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VERY INTERESTING**. \n",
    "\n",
    "\n",
    "The *NodePostProcessor* has been corrected to: *NodePostProccessor*, so there is no match in subjects! Nevertheless, we have obtained the *NodePostProccesor* node thanks to similarity search, which is great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Let's dive into the code and see how the `depth` parameter affects the behavior of\n",
      "the `__retrieve_relationship_nodes` method.\n",
      "Here's the relevant code:\n",
      "```python\n",
      "def __retrieve_relationship_nodes(self, base_id: str, node: Node, depth: int):\n",
      "    if base_id == str(node.id) or depth == 0:\n",
      "        return [node.id]\n",
      "    relations = []\n",
      "    node_relationships = node.node_relationships\n",
      "    if not node_relationships or not len(node_relationships):\n",
      "        return [node.id]\n",
      "    for id, _ in node_relationships.items():\n",
      "        node_ = self._db.get(Node, id)\n",
      "        relations.extend(self.__retrieve_relationship_nodes(base_id=base_id, node=node_, depth=depth-1))\n",
      "    return relations\n",
      "```\n",
      "The `depth` parameter controls how many levels of relationships are recursively traversed. Here's what happens\n",
      "when you change the value of `depth`:\n",
      "* If `depth` is 0, the method will only return the current node's ID (`node.id`).\n",
      "No recursive traversal will occur.\n",
      "* If `depth` is greater than 0, the method will recursively traverse the relationships of\n",
      "the current node, up to a maximum depth specified by the `depth` parameter. For each\n",
      "level of recursion, the method will:\n",
      "\t+ Check if the base ID matches the current node's ID or if the depth\n",
      "has been reached (i.e., `depth == 0`). If so, it returns a list containing only\n",
      "the current node's ID.\n",
      "\t+ Otherwise, it continues recursively traversing the relationships of the current node, decrementing the `depth`\n",
      "counter by 1 each time.\n",
      "In summary, changing the value of `depth` will control how many levels of relationships are\n",
      "recursively traversed. A higher value of `depth` means more levels of relationships will be explored,\n",
      "while a lower value (or 0) will limit the exploration to only the immediate neighbors\n",
      "or the current node itself.\n"
     ]
    }
   ],
   "source": [
    "formated_answer = format_answer(answer=answer, max_words=15)\n",
    "print(formated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subject is the function _create_node_relationships_file therefore the answer is complex because there is one subject.\u001b[0m\n",
      "\u001b[34mAgent answer: complex \n",
      "\u001b[0m\n",
      "\u001b[31mNot valid answer. Applying retries\u001b[0m\n",
      "\u001b[31m\tRetry agent response: {\"question_type\": \"complex\", \"subject\": [\"_create_node_relationships_file\"], \"reasoning\": \"The subject is _create_node_relationships_file function therefore there is only one subject, but the question involves the repository, so it's complex\"}\u001b[0m\n",
      "\u001b[31m\tRetry agent response: {\"question_type\": \"complex\", \"subject\": [\"_create_node_relationships_file\"], \"reasoning\": \"The subject is the function _create_node_relationships_file therefore the answer is complex because there is one function involved\"}\u001b[0m\n",
      "\u001b[31m\tRetry agent response: {\"question_type\": \"simple\", \"subject\": [\"_create_node_relationships_file\"], \"reasoning\": \"The subject is the function _create_node_relationships_file, therefore the answer is simple because there is only one subject.\"}\u001b[0m\n",
      "\u001b[34mAgent reasoning response: The question is about what will happen in the repository, which is different than the subject itself, therefore the answer is general.\u001b[0m\n",
      "\u001b[34mAgent answer: general \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: GeneralRetriever\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\tExact match of subject: {'_create_node_relationships_file'} in the database. --> 1\u001b[0m\n",
      "\u001b[34mScore: 1 for text: \n",
      "def _create_node_relationships_file(db: Session):\n",
      "    \n",
      "    fields = ('class_name', 'function_name', 'method_name')\n",
      "    name_file = os.environ['NAMES_FILE']\n",
      "    relationships_file = os.environ['RELATIONSHIPS_FILE']\n",
      "    \n",
      "    os.remove(name_file)\n",
      "    \n",
      "    if not os.path.exists(name_file):\n",
      "        nodes\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"What will happen in the repository If I remove the line 'os.remove(name_file)' of the function _create_node_relationships_file\"\n",
    "answer = asyncio.run(\n",
    "    query_pipeline(agent=multi_agent, \n",
    "                   query=query, \n",
    "                   llm=llm, \n",
    "                   db=db)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Let's dive into what happens if we remove the `os.remove(name_file)` line from the `_create_node_relationships_file` function.\n",
      "The original code removes the `name_file` before creating a new file with the same name.\n",
      "The `name_file` is used to store node metadata information. If we remove this line, the\n",
      "existing `name_file` will not be deleted, and the new contents will be appended to it\n",
      "instead of overwriting the previous contents.\n",
      "Here's an example of what might happen:\n",
      "1. The function creates a new file with the same name (`name_file`) as before.\n",
      "2. It then tries to read from this file and write to it, which would\n",
      "result in appending new data to the end of the existing file instead of overwriting\n",
      "it.\n",
      "This might cause issues if there are existing node metadata entries that need to be\n",
      "updated or deleted. The function will continue to append new data without clearing out any\n",
      "previous contents.\n",
      "To summarize: If we remove `os.remove(name_file)`, the existing `name_file` will not be deleted, and new\n",
      "contents will be appended to it instead of overwriting the previous contents.\n"
     ]
    }
   ],
   "source": [
    "formated_answer = format_answer(answer=answer, max_words=15)\n",
    "print(formated_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EDGE CASES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the retriever and the answer will be in case we are not carefull with the query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subject is the method check_relationships_of_retrieved_nodes therefore the answer is simple because there is only one subject\u001b[0m\n",
      "\u001b[34mAgent answer: simple \n",
      "\u001b[0m\n",
      "\u001b[34mAgent reasoning response: The question is regarding the method check_relationships_of_retrieved_nodes itself, therefore the answer is particular\u001b[0m\n",
      "\u001b[34mAgent answer: particular \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: SimilarityRetriever\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mOriginal Query: How does the method check_relationships_of_retrieved_nodes work?\u001b[0m\n",
      "\u001b[34m\tNew query to look with subject: check_relationships_of_retrieved_nodes -->  How does the method check_relationships_of_retrieved_nodes work?\u001b[0m\n",
      "\u001b[34mRelationships of node retrieve: 4\u001b[0m\n",
      "\u001b[34mScore: 0.8793947244412036 for text: \n",
      "    def _check_relationships_of_retrieved_nodes(self, depth: int) -> List[str]:\n",
      "        relations = []\n",
      "        for node in self._retrieved_nodes:\n",
      "            id = node.id\n",
      "            node_relationships = self._db.get(Node, id).node_relationships\n",
      "            if not node_relationships or not len(node_\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 1 for node --> 7f5b16db-5362-456e-8bc7-3273c1b96559:     def __retrieve_relationship_nodes(self, base_id: str, node: Node, depth: int):\n",
      "        if base_id == str(node.id) or depth == 0: \n",
      "            retu\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 2 for node --> 7f5b16db-5362-456e-8bc7-3273c1b96559:     def _check_relationships_of_retrieved_nodes(self, depth: int) -> List[str]:\n",
      "        relations = []\n",
      "        for node in self._retrieved_nodes:\n",
      "    \n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 3 for node --> 7f5b16db-5362-456e-8bc7-3273c1b96559: class Node(Base):\n",
      "\n",
      "    __tablename__ = \"node\"\n",
      "    id = Column(UUID(as_uuid=True), primary_key=True, index=True, default=uuid.uuid4)\n",
      "    node_type = Co\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 4 for node --> 7f5b16db-5362-456e-8bc7-3273c1b96559:     def _check_relationships_of_retrieved_nodes(self, depth: int) -> List[str]:\n",
      "        relations = []\n",
      "        for node in self._retrieved_nodes:\n",
      "    \n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"How does the method check_relationships_of_retrieved_nodes work?\"\n",
    "answer = asyncio.run(\n",
    "    query_pipeline(agent=multi_agent, \n",
    "                   query=query, \n",
    "                   llm=llm, \n",
    "                   db=db)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "I'm happy to explain how this method works!\n",
      "The `check_relationships_of_retrieved_nodes` method takes an integer parameter called `depth`. It returns a list of strings.\n",
      "Here's what it does:\n",
      "1. It initializes an empty list called `relations`.\n",
      "2. It iterates over each node in the `_retrieved_nodes` collection.\n",
      "3. For each node, it retrieves the node's ID and its relationships (stored in `_db.get(Node,\n",
      "id).node_relationships`).\n",
      "4. If the node has no relationships or if the relationships list is empty, it\n",
      "skips to the next iteration.\n",
      "5. For each relationship, it retrieves the related node (`self._db.get(Node, node_relationship_id)`) and calls another method\n",
      "(`__retrieve_relationship_nodes`) with the current node's ID, the related node, and the provided `depth`. This method\n",
      "presumably returns a list of nodes or IDs.\n",
      "6. It adds these returned relationships to the `relations` list using the `extend` method.\n",
      "In essence, this method is traversing a graph of nodes and their relationships, exploring up\n",
      "to the specified depth. The resulting list contains all the node IDs that are reachable\n",
      "within the provided depth from the original nodes in `_retrieved_nodes`.\n",
      "Here's the code snippet again for reference:\n",
      "```python\n",
      "def _check_relationships_of_retrieved_nodes(self, depth: int) -> List[str]:\n",
      "    relations = []\n",
      "    for node in self._retrieved_nodes:\n",
      "        id = node.id\n",
      "        node_relationships = self._db.get(Node, id).node_relationships\n",
      "        if not node_relationships or not len(node_relationships): continue\n",
      "        for node_relationship_id, _ in node_relationships.items():\n",
      "            node_ = self._db.get(Node,\n",
      "node_relationship_id)\n",
      "            relations.extend(self.__retrieve_relationship_nodes(base_id=id, node=node_, depth=depth))\n",
      "    return relations\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "formated_answer = format_answer(answer=answer, max_words=15)\n",
    "print(formated_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see, if we don't specify correctly the method, class or function, it performs a simple similarity search, so we may or not obtain the desired node.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subjects are the methods: _check_common_parent_nodes, _check_relationships_of_retrieved_nodes, return_nodes_after_apply_threshold_filter and return_nodes_with_score_after_apply_threshold_filter. These are multiple functions involved in the question, therefore it is complex.\u001b[0m\n",
      "\u001b[34mAgent answer: complex \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: SimilarityRetriever\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mOriginal Query: \n",
      "how do the methods: _check_common_parent_nodes, _check_relationships_of_retrieved_nodes, return_nodes_after_apply_threshold_filter and return_nodes_with_score_after_apply_threshold_filter work together \n",
      "to improve the result of the function query_vector_database?\n",
      "\u001b[0m\n",
      "\u001b[34m\tExact match of subject: return_nodes_after_apply_threshold_filter in the database. --> 1\u001b[0m\n",
      "\u001b[34m\tExact match of subject: _check_common_parent_nodes in the database. --> 1\u001b[0m\n",
      "\u001b[34m\tExact match of subject: _check_relationships_of_retrieved_nodes in the database. --> 1\u001b[0m\n",
      "\u001b[34m\tExact match of subject: return_nodes_with_score_after_apply_threshold_filter in the database. --> 1\u001b[0m\n",
      "\u001b[34m\tExact match of subject: query_vector_database in the database. --> 1\u001b[0m\n",
      "\u001b[34mScore: 1 for text: \n",
      "    def return_nodes_after_apply_threshold_filter(self):\n",
      "        return self._retrieved_nodes\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mScore: 1 for text: \n",
      "    def _check_common_parent_nodes(self) -> List[Tuple[str, int]]:\n",
      "        \n",
      "        parent_node_ids =  {}\n",
      "        file_of_node_ids = {}\n",
      "        \n",
      "        for node in self._retrieved_nodes_score:\n",
      "            \n",
      "            node: Node = node.node \n",
      "            file_id = node.file_id\n",
      "            \n",
      "         \n",
      "\u001b[0m\n",
      "\u001b[34mScore: 1 for text: \n",
      "    def _check_relationships_of_retrieved_nodes(self, depth: int) -> List[str]:\n",
      "        relations = []\n",
      "        for node in self._retrieved_nodes:\n",
      "            id = node.id\n",
      "            node_relationships = self._db.get(Node, id).node_relationships\n",
      "            if not node_relationships or not len(node_\n",
      "\u001b[0m\n",
      "\u001b[34mScore: 1 for text: \n",
      "    def return_nodes_with_score_after_apply_threshold_filter(self):\n",
      "        return self._retrieved_nodes_score\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mScore: 1 for text: \n",
      "async def query_vector_database(request: Request, db: Session = Depends(get_db)):\n",
      "    \n",
      "    import psycopg2\n",
      "    from pgvector.psycopg2 import register_vector\n",
      "    from .database.base import SQLALCHEMY_DATABASE_URL\n",
      "    import numpy as np\n",
      "    \n",
      "    body = await request.json()\n",
      "    code = body['code']\n",
      "    \n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "how do the methods: _check_common_parent_nodes, _check_relationships_of_retrieved_nodes, return_nodes_after_apply_threshold_filter and return_nodes_with_score_after_apply_threshold_filter work together \n",
    "to improve the result of the function query_vector_database?\n",
    "\"\"\"\n",
    "\n",
    "answer = asyncio.run(\n",
    "    query_pipeline(agent=multi_agent, \n",
    "                   query=query, \n",
    "                   llm=llm, \n",
    "                   db=db)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "I'd be happy to explain how these methods work together in the `query_vector_database` function.\n",
      "The methods `_check_common_parent_nodes`, `_check_relationships_of_retrieved_nodes`, `return_nodes_after_apply_threshold_filter`, and `return_nodes_with_score_after_apply_threshold_filter` are all part of a class called `NodePostProccesor`.\n",
      "This class is used to process the results of a vector database query, which returns\n",
      "a list of nodes with their corresponding distances from the original query code.\n",
      "Here's how these methods work together:\n",
      "1. `_check_common_parent_nodes`: This method takes in the retrieved nodes (which are returned by the `query_vector_database`\n",
      "function) and checks for common parent nodes and files. It does this by iterating over\n",
      "each node, checking if it's a method node (based on its type), and then counting\n",
      "the frequency of its parent nodes and file IDs. The method returns a list of\n",
      "tuples, where each tuple contains a parent node ID or file ID along with its\n",
      "frequency.\n",
      "2. `_check_relationships_of_retrieved_nodes`: This method takes in the retrieved nodes (again, returned by `query_vector_database`) and checks\n",
      "for relationships between these nodes. It does this by iterating over each node, retrieving its\n",
      "relationships, and then recursively checking the relationships of those connected nodes. The method returns a\n",
      "list of node IDs that are directly or indirectly related to the original query code.\n",
      "Now, let's see how these methods improve the results of `query_vector_database`:\n",
      "When you call `query_vector_database`, it executes a SQL query on your PostgreSQL database using psycopg2.\n",
      "This query retrieves the top 5 nodes that are most similar (based on cosine distance)\n",
      "to the original query code. The query returns a list of node IDs along with\n",
      "their distances from the query code.\n",
      "The results of this query are then processed by `NodePostProccesor`. The first method, `_check_common_parent_nodes`, takes\n",
      "these retrieved nodes and checks for common parent nodes and files. This helps filter out\n",
      "nodes that don't have many relationships or connections to other relevant nodes.\n",
      "The second method, `_check_relationships_of_retrieved_nodes`, recursively checks the relationships of these filtered nodes. This helps further\n",
      "refine the results by excluding nodes that are not directly or indirectly related to the\n",
      "original query code.\n",
      "Finally, the `return_nodes_after_apply_threshold_filter` and `return_nodes_with_score_after_apply_threshold_filter` methods return the filtered list of nodes with their corresponding\n",
      "scores (distances from the original query code). These methods apply a threshold filter based on\n",
      "the average score of all nodes. This helps remove any noisy or irrelevant results.\n",
      "So, in summary, these four methods work together to:\n",
      "1. Filter out nodes that don't have many relationships or connections.\n",
      "2. Recursively check relationships between filtered nodes.\n",
      "3. Apply a threshold filter based on the average node score.\n",
      "4. Return the final list of filtered nodes with their corresponding scores.\n",
      "By processing the query results in this way, `query_vector_database` can provide more accurate and relevant\n",
      "results for your vector database query.\n"
     ]
    }
   ],
   "source": [
    "formated_answer = format_answer(answer=answer, max_words=15)\n",
    "print(formated_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This has been a lucky try! Let's see if we can repeat the result...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
