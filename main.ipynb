{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`What is a subject?` $\\implies$ Any Python function, method, class or block of code. \n",
    "\n",
    "We need to create the Agent that will decide the tool to use based on a query. There will be two agents: \n",
    "1. **Simple vs Complex Agent**. This agent will classify the query of the user into one of these categories: \n",
    "\n",
    "- Simple:  Zero or nne subject present in the question. *Example: How does the function x work?*\n",
    "- Complex: More than one subject.  *Example: What are the differences between Class A and Class B?*\n",
    "\n",
    "- Tool returned: **`SimpleRetriever`**\n",
    "\n",
    "\n",
    "2. **General vs Particular Agent**. This agent will the output from the first agent only if the question type was: **`Simple`** and classify the question into one of two categories: \n",
    "\n",
    "- Particular: The question involves only the subject. *Example: How does the function x work?*\n",
    "- General: The question is formulated in such a way that the question does not have to do only with the subject. *Will my changes break anything?*\n",
    "\n",
    "- Tool returned: **`SimpleRetriever`** or **`GeneralRetriever`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from app.agent.multi_agent import MultiAgent\n",
    "from app.agent.agent import ContextTypeAgent, QuestionTypeAgent\n",
    "from app.prompts.prompts import SIMPLE_VS_COMPLEX, GENERAL_VS_PARTICULAR_CONTEXT\n",
    "from app.prompts.prompt import Prompt\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# simple vs complex -> 0-1 vs > 1 subjects\n",
    "simple_vs_complex_prompt = Prompt(prompt=SIMPLE_VS_COMPLEX)\n",
    "simple_vs_complex_agent = QuestionTypeAgent(\n",
    "    instruction=simple_vs_complex_prompt\n",
    ")\n",
    "\n",
    "# general vs particular\n",
    "general_vs_particular_prompt = Prompt(GENERAL_VS_PARTICULAR_CONTEXT)\n",
    "general_vs_particular_agent = ContextTypeAgent(\n",
    "    instruction=general_vs_particular_prompt\n",
    "    )\n",
    "\n",
    "multi_agent = MultiAgent(agents=[\n",
    "    simple_vs_complex_agent, \n",
    "    general_vs_particular_agent\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Classification Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We are going to test how the agent classify the questions and what tools does it choose to answer the question**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.database.base import get_db\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "db = next(get_db())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.retrievers.general_retriever import GeneralRetriever\n",
    "from app.retrievers.similarity_retriever import SimilarityRetriever\n",
    "\n",
    "\n",
    "async def tool_pipeline(agent: MultiAgent, query: str, db: Session=db):\n",
    "    tool, output = await agent.pipeline(query=query)\n",
    "    tool: GeneralRetriever | SimilarityRetriever = tool(db=db)\n",
    "    return tool.query_database(query=query, subjects=output.subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 General question retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This one is a tricky one because we are specifying a line of code besides the function. That is not an issue because of how our retrievers are built. We'll look to see if can find the subject based on the function name, method name or class name fields of the NodeMetadata.node_metadata column. That is why Postgres is so powerfull!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subject is the function _create_node_relationships_file therefore the answer is simple because there is only one subject\u001b[0m\n",
      "\u001b[34mAgent answer: simple \n",
      "\u001b[0m\n",
      "\u001b[34mAgent reasoning response: The question refers to what will happen when removing a line from the function, which is not about the subject itself, but about its effects, therefore the answer is general\u001b[0m\n",
      "\u001b[34mAgent answer: general \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: GeneralRetriever\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\tExact match of subject: {'_create_node_relationships_file'} in the database. --> 1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"What will happen If I remove the line 'os.remove(name_file)' of the function _create_node_relationships_file\"\n",
    "nodes, nodes_with_score = asyncio.run(tool_pipeline(agent=multi_agent, query=query, db=db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def _create_node_relationships_file(db: Session):\n",
      "    \n",
      "    fields = ('class_name', 'function_name', 'method_name')\n",
      "    name_file = os.environ['NAMES_FILE']\n",
      "    relationships_file = os.environ['RELATIONSHIPS_FILE']\n",
      "    \n",
      "    os.remove(name_file)\n",
      "    \n",
      "    if not os.path.exists(name_file):\n",
      "        nodes\n",
      "async def update_nodes_store(db: Session = Depends(get_db)):\n",
      "    updated_files = _create_file_node(path=os.environ['USER_CODE_DIRECTORY'], db=db)\n",
      "    _create_node_relationships_file(db=db)\n",
      "    return {\"py_files\": updated_files}\n",
      "\n",
      "async def upload_file_zip(file: UploadFile = File(...), db: Session = Depends(get_db)):\n",
      "\n",
      "    extract_dir = os.environ['USER_CODE_DIRECTORY']\n",
      "    if not os.path.exists(extract_dir):\n",
      "        # shutil.rmtree(extract_dir)\n",
      "        \n",
      "        os.makedirs(extract_dir, exist_ok=True)\n",
      "\n",
      "        with open(f\"{ext\n"
     ]
    }
   ],
   "source": [
    "# we print some of the nodes in which the function _create_node_relationships_file appears\n",
    "for node in nodes:\n",
    "    print(node.text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Particular Question retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's see one in which several retries have been needed to actually get a coherent answer: multiple subjects $\\implies$ complex question whereas one subject $\\implies$ simple.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subject is the class NodePostProccesor therefore the answer is complex because there is one class.\u001b[0m\n",
      "\u001b[34mAgent answer: complex \n",
      "\u001b[0m\n",
      "\u001b[31mNot valid answer. Applying retries\u001b[0m\n",
      "\u001b[31m\tRetry agent response: {\"question_type\": \"complex\", \"subject\": [\"NodePostProccesor\"], \"reasoning\": \"The subject is the class NodePostProccesor therefore the answer is complex because there is one subject\"}\u001b[0m\n",
      "\u001b[31m\tRetry agent response: {\"question_type\": \"complex\", \"subject\": [\"NodePostProccesor\"], \"reasoning\": \"The subject is the class NodePostProccesor therefore the answer is complex because there is only one subject, which is a class\"}\u001b[0m\n",
      "\u001b[31m\tRetry agent response: {\"question_type\": \"complex\", \"subject\": [\"NodePostProccesor\"], \"reasoning\": \"The subject is the class NodePostProccesor therefore the answer is complex because there is only one subject which is a class\"}\u001b[0m\n",
      "\u001b[31m\tRetry agent response: {\"question_type\": \"simple\", \"subject\": [\"NodePostProccesor\"], \"reasoning\": \"The subject is the class NodePostProccesor therefore the answer is simple because there is only one subject\"}\u001b[0m\n",
      "\u001b[34mAgent reasoning response: The question is regarding the implementation of the class NodePostProccesor itself, therefore the answer is particular\u001b[0m\n",
      "\u001b[34mAgent answer: particular \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: SimilarityRetriever\u001b[0m\n",
      "\u001b[34mOriginal Query: Explain to me how the class NodePostProccesor is implemented\u001b[0m\n",
      "\u001b[34m\tExact match of subject: NodePostProccesor in the database. --> 1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"Explain to me how the class NodePostProccesor is implemented\"\n",
    "nodes, _ = asyncio.run(tool_pipeline(agent=multi_agent, query=query, db=db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class NodePostProccesor:\n",
      "  \n",
      "    def __init__(self, retrieved_nodes_score: List[NodeWithScore], db: Session, score_threshold: float=0.8, min_parent_nodes: int=2, min_file_nodes: int=2):\n",
      "        \n",
      "        self._retrieved_nodes_score = [node for node in retrieved_nodes_score if node.score > score_thresh\n"
     ]
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    print(node.text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see, the output has modified the name of the subject: NodePostProcesor has changed to NodePostProcessor. This implies that we won't get a perfect match from the database, so similarity search will be performed. We still get the appropiate Node.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subject is NodePostProccesor class therefore the answer is complex because there is one subject.\u001b[0m\n",
      "\u001b[34mAgent answer: complex \n",
      "\u001b[0m\n",
      "\u001b[31mNot valid answer. Applying retries\u001b[0m\n",
      "\u001b[31m\tRetry agent response: {\"question_type\": \"simple\", \"subject\": [\"NodePostProcessor\"], \"reasoning\": \"The subject is NodePostProcessor, therefore the answer is simple because there is only one subject\"}\u001b[0m\n",
      "\u001b[34mAgent reasoning response: The question is regarding the implementation of NodePostProcessor itself, therefore the answer is particular\u001b[0m\n",
      "\u001b[34mAgent answer: particular \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: SimilarityRetriever\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mOriginal Query: Explain to me how NodePostProccesor is implemented\u001b[0m\n",
      "\u001b[34m\tNew query to look with subject: NodePostProcessor -->  explain to me how nodepostproccesor is implemented\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# let's try again with the same question but removing the word class\n",
    "# this time it gets a coherent answer faster\n",
    "query = \"Explain to me how NodePostProccesor is implemented\"\n",
    "nodes = asyncio.run(tool_pipeline(agent=multi_agent, query=query, db=db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class NodePostProccesor:\n",
      "  \n",
      "    def __init__(self, retrieved_nodes_score: List[NodeWithScore], db: Session, score_threshold: float=0.8, min_parent_nodes: int=2, min_file_nodes: int=2):\n",
      "        \n",
      "        self._retrieved_nodes_score = [node for node in retrieved_nodes_score if node.score > score_thresh\n"
     ]
    }
   ],
   "source": [
    "for node in nodes[0]:\n",
    "    print(node.text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Complex question retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we want our Agent to identify multiple subjects.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subjects are: _create_file_node function and _create_nodes_of_file function, therefore the answer is complex because there are more than one subject.\u001b[0m\n",
      "\u001b[34mAgent answer: complex \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: SimilarityRetriever\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mOriginal Query: How does the function _create_file_node depend on the function _create_nodes_of_file?\u001b[0m\n",
      "\u001b[34m\tExact match of subject: _create_file_node in the database. --> 1\u001b[0m\n",
      "\u001b[34m\tExact match of subject: _create_nodes_of_file in the database. --> 1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"How does the function _create_file_node depend on the function _create_nodes_of_file?\"\n",
    "nodes, _ = asyncio.run(tool_pipeline(agent=multi_agent, query=query, db=db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def _create_file_node(path: str, db: Session):\n",
      "    updated_files = []\n",
      "    for root, _, files in os.walk(path):\n",
      "        for file in files:\n",
      "            lines = open(os.path.join(root, file), \"r\").readlines()\n",
      "            text = \"\".join(lines)\n",
      "            hash = calculate_hash(text)\n",
      "            file = F\n",
      "def _create_nodes_of_file(path: str, db: Session, file_id: str):\n",
      "    files_structure_folder = os.environ['FILES_STRUCTURE_FOLDER']\n",
      "    os.makedirs(files_structure_folder, exist_ok=True)\n",
      "    \n",
      "    if path.startswith(\".\"): path = path[2:]\n",
      "    elif path.startswith(\"..\"): path = path[3:]\n",
      "    \n",
      "    file_na\n"
     ]
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    print(node.text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Question-Answer with agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that we've seen that our agent classify properly some questions, let's actually find an answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.agent.llama_client import LlamaClient\n",
    "from app.printer import Printer\n",
    "from app.prompts.prompts import PROMPT_TO_ANSWER_QUESTIONS\n",
    "\n",
    "printer = Printer()\n",
    "query = \"How does the function _create_file_node depend on the function _create_nodes_of_file?\"\n",
    "\n",
    "llm = LlamaClient()\n",
    "\n",
    "def format_answer(answer: str, max_words: int) -> str:\n",
    "    answer = answer.replace(\"\\n\\n\", \"\\n\")\n",
    "    lines = answer.split(\"\\n\")\n",
    "    processed_answer = \" \"\n",
    "    for line in lines:\n",
    "        words = line.split(\" \")\n",
    "        for k in range(0, len(words), max_words):\n",
    "            processed_line = \" \".join(words[k: k + max_words])\n",
    "            processed_answer += \"\\n\" + processed_line\n",
    "    return processed_answer\n",
    "\n",
    "async def query_pipeline(agent: MultiAgent, \n",
    "                         query: str, \n",
    "                         llm: LlamaClient, \n",
    "                         db: Session) -> str:\n",
    "    tool, output = await agent.pipeline(query=query)\n",
    "    tool: GeneralRetriever | SimilarityRetriever = tool(db=db)\n",
    "    nodes, nodes_with_score = tool.query_database(query=query, subjects=output.subject)\n",
    "    for node_with_score in nodes_with_score:\n",
    "        printer.print_blue(f\"Score: {node_with_score.score} for text: \\n{node_with_score.node.text[:300]}\\n\")\n",
    "    context = \"\\n\".join([node.text for node in nodes])\n",
    "    prompt = Prompt.format_prompt(prompt=PROMPT_TO_ANSWER_QUESTIONS, context=context, query=query)\n",
    "    answer = await llm.acall(query=prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subjects are: _create_file_node function and _create_nodes_of_file function, therefore the answer is complex because there are more than one subject.\u001b[0m\n",
      "\u001b[34mAgent answer: complex \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: SimilarityRetriever\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mOriginal Query: How does the function _create_file_node depend on the function _create_nodes_of_file?\u001b[0m\n",
      "\u001b[34m\tExact match of subject: _create_file_node in the database. --> 1\u001b[0m\n",
      "\u001b[34m\tExact match of subject: _create_nodes_of_file in the database. --> 1\u001b[0m\n",
      "\u001b[34mScore: 1 for text: \n",
      "def _create_file_node(path: str, db: Session):\n",
      "    updated_files = []\n",
      "    for root, _, files in os.walk(path):\n",
      "        for file in files:\n",
      "            lines = open(os.path.join(root, file), \"r\").readlines()\n",
      "            text = \"\".join(lines)\n",
      "            hash = calculate_hash(text)\n",
      "            file = F\n",
      "\u001b[0m\n",
      "\u001b[34mScore: 1 for text: \n",
      "def _create_nodes_of_file(path: str, db: Session, file_id: str):\n",
      "    files_structure_folder = os.environ['FILES_STRUCTURE_FOLDER']\n",
      "    os.makedirs(files_structure_folder, exist_ok=True)\n",
      "    \n",
      "    if path.startswith(\".\"): path = path[2:]\n",
      "    elif path.startswith(\"..\"): path = path[3:]\n",
      "    \n",
      "    file_na\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "answer = asyncio.run(\n",
    "    query_pipeline(agent=multi_agent, \n",
    "                   query=query, \n",
    "                   llm=llm, \n",
    "                   db=db)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "The function `_create_file_node` depends on the function `_create_nodes_of_file` in the following ways:\n",
      "1. In the `_create_file_node` function, when a new file is found, it calls the `_create_nodes_of_file`\n",
      "function to create nodes for that file. This is evident from the line `db.commit()` and\n",
      "then calling `_create_nodes_of_file` with the `file_path` and `db`.\n",
      "2. The `_create_nodes_of_file` function is called twice in the `_create_file_node` function, once when a new\n",
      "file is found, and again after updating the existing file.\n",
      "Therefore, the function `_create_file_node` relies on the functionality of the `_create_nodes_of_file` function to create nodes\n",
      "for each file.\n"
     ]
    }
   ],
   "source": [
    "formated_answer = format_answer(answer=answer, max_words=15)\n",
    "print(formated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subject is the __retrieve_relationship_nodes method, therefore the answer is simple since there is only one subject\u001b[0m\n",
      "\u001b[34mAgent answer: simple \n",
      "\u001b[0m\n",
      "\u001b[34mAgent reasoning response: The question involves the effect, which is different than the subject, therefore the answer is general.\u001b[0m\n",
      "\u001b[34mAgent answer: general \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: GeneralRetriever\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\tExact match of subject: {'__retrieve_relationship_nodes'} in the database. --> 1\u001b[0m\n",
      "\u001b[34mScore: 1 for text: \n",
      "    def __retrieve_relationship_nodes(self, base_id: str, node: Node, depth: int):\n",
      "        if base_id == str(node.id) or depth == 0: \n",
      "            return [node.id]\n",
      "        relations = []\n",
      "        node_relationships = node.node_relationships\n",
      "        if not node_relationships or not len(node_relationshi\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"If I change the parameter depth of the method: __retrieve_relationship_nodes what effect will that have?\"\n",
    "answer = asyncio.run(\n",
    "    query_pipeline(agent=multi_agent, \n",
    "                   query=query, \n",
    "                   llm=llm, \n",
    "                   db=db)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "A great question!\n",
      "The `depth` parameter in the `__retrieve_relationship_nodes` method controls how many levels of relationships are retrieved.\n",
      "Let's look at the code:\n",
      "```python\n",
      "def __retrieve_relationship_nodes(self, base_id: str, node: Node, depth: int):\n",
      "    ...\n",
      "    if depth == 0:\n",
      "        return [node.id]\n",
      "    ...\n",
      "    relations.extend(self.__retrieve_relationship_nodes(base_id=base_id, node=node_, depth=depth-1))\n",
      "```\n",
      "As you can see, the method calls itself recursively with a decreasing `depth` value until\n",
      "it reaches `depth == 0`. When `depth` is 0, it simply returns a list containing\n",
      "the ID of the current node.\n",
      "If you change the `depth` parameter, you'll affect how many levels of relationships are retrieved:\n",
      "* If `depth` is increased (e.g., from 2 to 3), more levels of relationships will\n",
      "be retrieved.\n",
      "* If `depth` is decreased (e.g., from 2 to 1), fewer levels of relationships will\n",
      "be retrieved.\n",
      "For example, if you call the method with `depth=2`, it will retrieve all relationships at\n",
      "level 1 and then recursively retrieve relationships at level 0 for each node at level\n",
      "1. If you call it with `depth=3`, it will also retrieve relationships at level 2\n",
      "for each node at level 1.\n",
      "So, changing the `depth` parameter controls the depth of the recursive relationship retrieval process.\n"
     ]
    }
   ],
   "source": [
    "formated_answer = format_answer(answer=answer, max_words=15)\n",
    "print(formated_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same question, but know another subject is involved to confuse the Agent. The *NodePostProccesor* class is the parent class of the method *__retrieve_relationships_nodes*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subjects are: NodePostProcessor class and __retrieve_relationship_nodes method, therefore the answer is complex because there are more than one subject.\u001b[0m\n",
      "\u001b[34mAgent answer: complex \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: SimilarityRetriever\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mOriginal Query: If I change the parameter depht of the method: __retrieve_relationship_nodes of the class NodePostProccesor what effect will that have?\u001b[0m\n",
      "\u001b[34m\tNew query to look with subject: NodePostProcessor -->  if i change the parameter depht of the method: __retrieve_relationship_nodes of the class nodepostproccesor what effect will that have?\u001b[0m\n",
      "\u001b[34m\tExact match of subject: __retrieve_relationship_nodes in the database. --> 1\u001b[0m\n",
      "\u001b[34mScore: 0.760384105455402 for text: \n",
      "class NodePostProccesor:\n",
      "  \n",
      "    def __init__(self, retrieved_nodes_score: List[NodeWithScore], db: Session, score_threshold: float=0.8, min_parent_nodes: int=2, min_file_nodes: int=2):\n",
      "        \n",
      "        self._retrieved_nodes_score = [node for node in retrieved_nodes_score if node.score > score_thresh\n",
      "\u001b[0m\n",
      "\u001b[34mScore: 1 for text: \n",
      "    def __retrieve_relationship_nodes(self, base_id: str, node: Node, depth: int):\n",
      "        if base_id == str(node.id) or depth == 0: \n",
      "            return [node.id]\n",
      "        relations = []\n",
      "        node_relationships = node.node_relationships\n",
      "        if not node_relationships or not len(node_relationshi\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"If I change the parameter depth of the method: __retrieve_relationship_nodes of the class NodePostProccesor what effect will that have?\"\n",
    "answer = asyncio.run(\n",
    "    query_pipeline(agent=multi_agent, \n",
    "                   query=query, \n",
    "                   llm=llm, \n",
    "                   db=db)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VERY INTERESTING**. \n",
    "\n",
    "\n",
    "The *NodePostProcessor* has been corrected to: *NodePostProccessor*, so there is no match in subjects! Nevertheless, we have obtained the *NodePostProccesor* node thanks to similarity search, which is great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Let's dive into the code and see how the `depth` parameter affects the behavior of\n",
      "the `__retrieve_relationship_nodes` method.\n",
      "Here's the relevant code:\n",
      "```python\n",
      "def __retrieve_relationship_nodes(self, base_id: str, node: Node, depth: int):\n",
      "    if base_id == str(node.id) or depth == 0:\n",
      "        return [node.id]\n",
      "    relations = []\n",
      "    node_relationships = node.node_relationships\n",
      "    if not node_relationships or not len(node_relationships):\n",
      "        return [node.id]\n",
      "    for id, _ in node_relationships.items():\n",
      "        node_ = self._db.get(Node, id)\n",
      "        relations.extend(self.__retrieve_relationship_nodes(base_id=base_id, node=node_, depth=depth-1))\n",
      "    return relations\n",
      "```\n",
      "The `depth` parameter controls how many levels of relationships are recursively traversed. Here's what happens\n",
      "when you change the value of `depth`:\n",
      "* If `depth` is 0, the method will only return the current node's ID (`node.id`).\n",
      "No recursive traversal will occur.\n",
      "* If `depth` is greater than 0, the method will recursively traverse the relationships of\n",
      "the current node, up to a maximum depth specified by the `depth` parameter. For each\n",
      "level of recursion, the method will:\n",
      "\t+ Check if the base ID matches the current node's ID or if the depth\n",
      "has been reached (i.e., `depth == 0`). If so, it returns a list containing only\n",
      "the current node's ID.\n",
      "\t+ Otherwise, it continues recursively traversing the relationships of the current node, decrementing the `depth`\n",
      "counter by 1 each time.\n",
      "In summary, changing the value of `depth` will control how many levels of relationships are\n",
      "recursively traversed. A higher value of `depth` means more levels of relationships will be explored,\n",
      "while a lower value (or 0) will limit the exploration to only the immediate neighbors\n",
      "or the current node itself.\n"
     ]
    }
   ],
   "source": [
    "formated_answer = format_answer(answer=answer, max_words=15)\n",
    "print(formated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subject is the function _create_node_relationships_file therefore the answer is complex because there is only one subject\u001b[0m\n",
      "\u001b[34mAgent answer: complex \n",
      "\u001b[0m\n",
      "\u001b[31mNot valid answer. Applying retries\u001b[0m\n",
      "\u001b[31m\tRetry agent response: {\"question_type\": \"simple\", \"subject\": [\"os\"], \"reasoning\": \"The subject is the os function therefore the answer is simple because there is only one subject.\"}\u001b[0m\n",
      "\u001b[34mAgent reasoning response: The question involves the repository, which is different than the subject, therefore the answer is general.\u001b[0m\n",
      "\u001b[34mAgent answer: general \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: GeneralRetriever\u001b[0m\n",
      "\u001b[32mMetadata of the node that we're considering: {'arguments': 'db: Session', 'function_name': '_create_node_relationships_file'}\u001b[0m\n",
      "\u001b[32mMetadata of the node that we're considering: {'arguments': 'db: Session = Depends', 'function_name': 'update_nodes_store'}\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat will happen in the repository If I remove the line \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mos.remove(name_file)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m of the function _create_node_relationships_file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m~/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:314\u001b[0m, in \u001b[0;36mTask.__step_run_and_handle_result\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "Cell \u001b[0;32mIn[36], line 27\u001b[0m, in \u001b[0;36mquery_pipeline\u001b[0;34m(agent, query, llm, db)\u001b[0m\n\u001b[1;32m     25\u001b[0m tool, output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m agent\u001b[38;5;241m.\u001b[39mpipeline(query\u001b[38;5;241m=\u001b[39mquery)\n\u001b[1;32m     26\u001b[0m tool: GeneralRetriever \u001b[38;5;241m|\u001b[39m SimilarityRetriever \u001b[38;5;241m=\u001b[39m tool(db\u001b[38;5;241m=\u001b[39mdb)\n\u001b[0;32m---> 27\u001b[0m nodes, nodes_with_score \u001b[38;5;241m=\u001b[39m \u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_database\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node_with_score \u001b[38;5;129;01min\u001b[39;00m nodes_with_score:\n\u001b[1;32m     29\u001b[0m     printer\u001b[38;5;241m.\u001b[39mprint_blue(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_with_score\u001b[38;5;241m.\u001b[39mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for text: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnode_with_score\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mtext[:\u001b[38;5;241m300\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Project-Ideas/python-gpt/app/retrievers/general_retriever.py:125\u001b[0m, in \u001b[0;36mGeneralRetriever.query_database\u001b[0;34m(self, query, subjects)\u001b[0m\n\u001b[1;32m    122\u001b[0m             valid_node \u001b[38;5;241m=\u001b[39m top_node\n\u001b[1;32m    123\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m valid_node_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mvalid_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m)\n\u001b[1;32m    126\u001b[0m all_nodes_related_to_this_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_db\u001b[38;5;241m.\u001b[39mquery(Node)\u001b[38;5;241m.\u001b[39mfilter(Node\u001b[38;5;241m.\u001b[39mnode_relationships\u001b[38;5;241m.\u001b[39mhas_key(valid_node_id))\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [valid_node] \u001b[38;5;241m+\u001b[39m all_nodes_related_to_this_node, nodes_with_score\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'id'"
     ]
    }
   ],
   "source": [
    "query = \"What will happen in the repository If I remove the line 'os.remove(name_file)' of the function _create_node_relationships_file\"\n",
    "answer = asyncio.run(\n",
    "    query_pipeline(agent=multi_agent, \n",
    "                   query=query, \n",
    "                   llm=llm, \n",
    "                   db=db)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
