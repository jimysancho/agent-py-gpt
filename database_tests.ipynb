{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from app.database.base import get_db\n",
    "from app.database.models import Node, NodeMetadata\n",
    "from app.retrievers.similarity_retriever import SimilarityRetriever\n",
    "from app.retrievers.general_retriever import GeneralRetriever\n",
    "\n",
    "db = next(get_db())\n",
    "sim_retriever = SimilarityRetriever(db=db)\n",
    "general_retriever = GeneralRetriever(db=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mMetadata of the node that we're considering: {'class_name': 'NodePostProccesor', 'parent_class': ''}\u001b[0m\n",
      "\u001b[34mThe chosen node is a class node\u001b[0m\n",
      "\u001b[34m\t{'hash': '6dac94369cf4565df6edf989b31b601fb68aef57d441db4bcb0ec2a5aed7ff7b', 'lines_of_code': [7, 78], 'additional_metadata': {'class_name': 'NodePostProccesor', 'parent_class': ''}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# query = \"What will happen If I remove the line: os.remove(name_file) of the function _create_node_relationships_file\"\n",
    "query = \"Explain to me how the class NodePostProccesor is implemented\"\n",
    "sim_nodes, _ = sim_retriever._retrieve_nodes(query=query)\n",
    "gen_nodes = general_retriever.query_database(\n",
    "    query=query, \n",
    "    subjects={'NodePostProccesor'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class NodePostProccesor:\n",
      "  \n",
      "    def __init__(self, retrieved_nodes_score: List[NodeWithScore], db: Session, score_threshold: float=0.8, min_parent_nodes: int=2, min_file_nodes: int=2):\n",
      "        \n",
      "        self._retrieved_nodes_score = [node for node in retrieved_nodes_score if node.score > score_threshold]\n",
      "        self._retrieved_nodes = [node.node for node in self._retrieved_nodes_score]\n",
      "        \n",
      "        self._score_threshold = score_threshold\n",
      "        self._db = db \n",
      "        \n",
      "        self._retrieved_nodes_types = self._check_retrieved_nodes_type(retrieved_nodes_score)\n",
      "\n",
      "        self._min_parent_nodes = min_parent_nodes\n",
      "        self._min_file_nodes = min_file_nodes\n",
      "        \n",
      "    def return_nodes_after_apply_threshold_filter(self):\n",
      "        return self._retrieved_nodes\n",
      "    \n",
      "    def return_nodes_with_score_after_apply_threshold_filter(self):\n",
      "        return self._retrieved_nodes_score\n",
      "    \n",
      "    def _check_retrieved_nodes_type(self, nodes: List[NodeWithScore]) -> List[NodeType]:\n",
      "        _types = []\n",
      "        for node in nodes:\n",
      "            node_type: NodeType = node.node.node_type\n",
      "            _types.append(node_type)\n",
      "            \n",
      "        return _types \n",
      "    \n",
      "    def _check_common_parent_nodes(self) -> List[Tuple[str, int]]:\n",
      "        \n",
      "        parent_node_ids =  {}\n",
      "        file_of_node_ids = {}\n",
      "        \n",
      "        for node in self._retrieved_nodes_score:\n",
      "            \n",
      "            node: Node = node.node \n",
      "            file_id = node.file_id\n",
      "            \n",
      "            if node.node_type.value == NodeType.METHOD.value:\n",
      "                parent_node_id = node.parent_node_id\n",
      "                parent_node_ids[parent_node_id] = 1 if parent_node_id not in parent_node_ids else parent_node_ids[parent_node_id] + 1\n",
      "            file_of_node_ids[file_id] = 1 if file_id not in file_of_node_ids else file_of_node_ids[file_id] + 1\n",
      "        \n",
      "        return [\n",
      "            [(parent_node_id, frequency) for (parent_node_id, frequency) in parent_node_ids.items() if frequency >= self._min_parent_nodes], \n",
      "            [(file_id, frequency) for (file_id, frequency) in file_of_node_ids.items() if frequency >= self._min_file_nodes]\n",
      "        ]\n",
      "        \n",
      "    def _check_relationships_of_retrieved_nodes(self, depth: int) -> List[str]:\n",
      "        relations = []\n",
      "        for node in self._retrieved_nodes:\n",
      "            id = node.id\n",
      "            node_relationships = self._db.get(Node, id).node_relationships\n",
      "            if not node_relationships or not len(node_relationships): continue\n",
      "            for node_relationship_id, _ in node_relationships.items():\n",
      "                node_ = self._db.get(Node, node_relationship_id)\n",
      "                relations.extend(self.__retrieve_relationship_nodes(base_id=id, node=node_, depth=depth))\n",
      "                # relations.append(node_.id)\n",
      "        return relations\n",
      "\n",
      "    def __retrieve_relationship_nodes(self, base_id: str, node: Node, depth: int):\n",
      "        if base_id == str(node.id) or depth == 0: \n",
      "            return [node.id]\n",
      "        relations = []\n",
      "        node_relationships = node.node_relationships\n",
      "        if not node_relationships or not len(node_relationships):\n",
      "            return [node.id]\n",
      "        for id, _ in node_relationships.items():\n",
      "            node_ = self._db.get(Node, id)\n",
      "            relations.extend(self.__retrieve_relationship_nodes(base_id=base_id, node=node_, depth=depth-1))\n",
      "        return relations        \n",
      "\n",
      "async def query_vector_database(request: Request, db: Session = Depends(get_db)):\n",
      "    \n",
      "    import psycopg2\n",
      "    from pgvector.psycopg2 import register_vector\n",
      "    from .database.base import SQLALCHEMY_DATABASE_URL\n",
      "    import numpy as np\n",
      "    \n",
      "    body = await request.json()\n",
      "    code = body['code']\n",
      "    code_embedding = create_embedding(query=code)\n",
      "    \n",
      "    conn = psycopg2.connect(SQLALCHEMY_DATABASE_URL)\n",
      "    register_vector(conn)\n",
      "    cur = conn.cursor()\n",
      "    cur.execute(\"\"\"\n",
      "        SELECT id, 1 - cosine_distance(embedding_text_1536, %s::vector) AS similarity \n",
      "        FROM node \n",
      "        ORDER BY similarity DESC \n",
      "        LIMIT 5;\n",
      "    \"\"\", (code_embedding,))\n",
      "    \n",
      "    nodes_with_distances = cur.fetchall()\n",
      "    nodes = []\n",
      "    nodes_with_score = []\n",
      "    for node_id, distance in nodes_with_distances:\n",
      "        node = db.get(models.Node, node_id)\n",
      "        file_of_node = db.query(models.File).filter(models.File.id == node.file_id).first()\n",
      "        nodes_with_score.append(NodeWithScore(node=node, score=distance))\n",
      "        nodes.append([node.id, node.text, distance, file_of_node.path])\n",
      "        \n",
      "    score_mean = np.mean([n.score for n in nodes_with_score])\n",
      "    node_post_proccesor = NodePostProccesor(retrieved_nodes_score=nodes_with_score, db=db, score_threshold=score_mean)\n",
      "    parent_node_freq, file_node_freq = node_post_proccesor._check_common_parent_nodes()\n",
      "    relations = node_post_proccesor._check_relationships_of_retrieved_nodes(depth=3)\n",
      "    relationships_nodes = []\n",
      "    for node_id in relations:\n",
      "        relationships_nodes.append([node_id, db.get(models.Node, node_id).text])\n",
      "        \n",
      "    nodes = node_post_proccesor.return_nodes_after_apply_threshold_filter()\n",
      "    nodes_with_score = node_post_proccesor.return_nodes_with_score_after_apply_threshold_filter()\n",
      "    return_nodes = [[n.node.id, n.node.text, n.score] for n in nodes_with_score]\n",
      "        \n",
      "    return {\"nodes\": return_nodes, \n",
      "            \"parent_nodes\": parent_node_freq, \n",
      "            \"file_node\": file_node_freq, \n",
      "            \"relations\": relationships_nodes}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for node in gen_nodes:\n",
    "    print(node.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
