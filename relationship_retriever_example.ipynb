{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from app.agent.multi_agent import MultiAgent\n",
    "from app.agent.agent import ContextTypeAgent, QuestionTypeAgent\n",
    "from app.prompts.prompts import SIMPLE_VS_COMPLEX, GENERAL_VS_PARTICULAR_CONTEXT\n",
    "from app.prompts.prompt import Prompt\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# simple vs complex -> 0-1 vs > 1 subjects\n",
    "simple_vs_complex_prompt = Prompt(prompt=SIMPLE_VS_COMPLEX)\n",
    "simple_vs_complex_agent = QuestionTypeAgent(\n",
    "    instruction=simple_vs_complex_prompt\n",
    ")\n",
    "\n",
    "# general vs particular\n",
    "general_vs_particular_prompt = Prompt(GENERAL_VS_PARTICULAR_CONTEXT)\n",
    "general_vs_particular_agent = ContextTypeAgent(\n",
    "    instruction=general_vs_particular_prompt\n",
    "    )\n",
    "\n",
    "multi_agent = MultiAgent(agents=[\n",
    "    simple_vs_complex_agent, \n",
    "    general_vs_particular_agent\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.database.base import get_db\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "db = next(get_db())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.retrievers.general_retriever import GeneralRetriever\n",
    "from app.retrievers.similarity_retriever import SimilarityRetriever\n",
    "from app.retrievers.relationships_retriever import RelationShipRetriever\n",
    "\n",
    "\n",
    "async def tool_pipeline(agent: MultiAgent, query: str, db: Session=db):\n",
    "    tool, output = await agent.pipeline(query=query)\n",
    "    tool: GeneralRetriever | SimilarityRetriever = tool(db=db)\n",
    "    return tool.query_database(query=query, subjects=output.subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.agent.llama_client import LlamaClient\n",
    "from app.printer import Printer\n",
    "from app.prompts.prompts import PROMPT_TO_ANSWER_QUESTIONS\n",
    "\n",
    "printer = Printer()\n",
    "query = \"How does the function _create_file_node depend on the function _create_nodes_of_file?\"\n",
    "THRESHOLD = 0.25\n",
    "\n",
    "llm = LlamaClient()\n",
    "\n",
    "def format_answer(answer: str, max_words: int) -> str:\n",
    "    answer = answer.replace(\"\\n\\n\", \"\\n\")\n",
    "    lines = answer.split(\"\\n\")\n",
    "    processed_answer = \" \"\n",
    "    for line in lines:\n",
    "        words = line.split(\" \")\n",
    "        for k in range(0, len(words), max_words):\n",
    "            processed_line = \" \".join(words[k: k + max_words])\n",
    "            processed_answer += \"\\n\" + processed_line\n",
    "    return processed_answer\n",
    "\n",
    "async def query_pipeline(agent: MultiAgent, \n",
    "                         query: str, \n",
    "                         llm: LlamaClient, \n",
    "                         db: Session, \n",
    "                         threshold: float=THRESHOLD) -> str:\n",
    "    \n",
    "    tool, output = await agent.pipeline(query=query)\n",
    "    tool: GeneralRetriever | SimilarityRetriever = tool(db=db)\n",
    "    nodes, nodes_with_score, relationships = tool.query_database(query=query, subjects=output.subject)\n",
    "    for node_with_score in nodes_with_score:\n",
    "        printer.print_blue(f\"Score: {node_with_score.score} for text: \\n{node_with_score.node.text[:300]}\\n\")\n",
    "    filtered_relationships = {}\n",
    "    if relationships: \n",
    "        for relation, relation_nodes in relationships.items():\n",
    "            for n, rel_node in enumerate(relation_nodes):\n",
    "                printer.print_blue(f\"\\tRelationship {n+1} for node --> {relation}: \\n{rel_node.text[:150]}\\n\")\n",
    "        relationship_retriever = RelationShipRetriever(query=query, nodes=nodes, relationships=relationships)\n",
    "        filtered_relationships = relationship_retriever.filter_relationships(threshold=threshold)\n",
    "    context = \"\\n\".join([node.text for node in nodes])\n",
    "    context += \"\\n\".join([node.text for relation_node in filtered_relationships.values() for node in relation_node]) if len(filtered_relationships) else \"\"\n",
    "    prompt = Prompt.format_prompt(prompt=PROMPT_TO_ANSWER_QUESTIONS, context=context, query=query)\n",
    "    answer = await llm.acall(query=prompt)\n",
    "    return answer, relationships, filtered_relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subject is the method __retrieve_relationship_nodes therefore the answer is simple because there is only one subject\u001b[0m\n",
      "\u001b[34mAgent answer: simple \n",
      "\u001b[0m\n",
      "\u001b[34mAgent reasoning response: The question involves an unspecified effect, which is different than the subject, therefore the answer is general.\u001b[0m\n",
      "\u001b[34mAgent answer: general \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: GeneralRetriever\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\tExact match of subject: {'__retrieve_relationship_nodes'} in the database. --> 1\u001b[0m\n",
      "\u001b[34mScore: 1 for text: \n",
      "    def __retrieve_relationship_nodes(self, base_id: str, node: Node, depth: int):\n",
      "        if base_id == str(node.id) or depth == 0: \n",
      "            return [node.id]\n",
      "        relations = []\n",
      "        node_relationships = node.node_relationships\n",
      "        if not node_relationships or not len(node_relationshi\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 1 for node --> 3e63f0f0-81cc-4e00-bfe1-bef785b07b94: \n",
      "class Node(Base):\n",
      "\n",
      "    __tablename__ = \"node\"\n",
      "    id = Column(UUID(as_uuid=True), primary_key=True, index=True, default=uuid.uuid4)\n",
      "    node_type = Co\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\tFiltered relationships -> Before filtering: 1. After: 1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"If I change the parameter depth of the method: __retrieve_relationship_nodes what effect will that have?\"\n",
    "answer, relationships, filterd_relationships = asyncio.run(\n",
    "    query_pipeline(agent=multi_agent, \n",
    "                   query=query, \n",
    "                   llm=llm, \n",
    "                   db=db)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Let's dive into it!\n",
      "The `depth` parameter in the `__retrieve_relationship_nodes` method controls how many levels of relationships to retrieve.\n",
      "\n",
      "If you increase the value of `depth`, this method will recursively traverse more levels of\n",
      "relationships. For example, if you set `depth=1`, it will only retrieve direct child nodes of\n",
      "the input node. If you set `depth=2`, it will also retrieve the children's children (grandchildren),\n",
      "and so on.\n",
      "On the other hand, decreasing the value of `depth` will limit the depth of the\n",
      "relationship traversal. For instance, if you set `depth=0`, it will only return the ID of\n",
      "the input node itself, without any relationships. If you set `depth=-1`, it will raise a\n",
      "`ValueError`.\n",
      "Here's an example to illustrate this:\n",
      "```\n",
      "def __retrieve_relationship_nodes(self, base_id: str, node: Node, depth: int):\n",
      "    # ...\n",
      "    if depth == 0:\n",
      "        return [node.id]  # only the input\n",
      "node itself\n",
      "    for id, _ in node_relationships.items():\n",
      "        node_ = self._db.get(Node, id)\n",
      "        relations.extend(self.__retrieve_relationship_nodes(base_id=base_id, node=node_, depth=depth-1))  # recursive call\n",
      "with decreased depth\n",
      "    return relations\n",
      "```\n",
      "In this example, the method will recursively traverse relationships up to the specified `depth`. If\n",
      "you increase the value of `depth`, it will explore more levels of relationships.\n",
      "Does that help clarify things?\n"
     ]
    }
   ],
   "source": [
    "answer = format_answer(answer=answer, max_words=15)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subject is the function query_vector_database therefore the answer is simple because there is only one subject.\u001b[0m\n",
      "\u001b[34mAgent answer: simple \n",
      "\u001b[0m\n",
      "\u001b[34mAgent reasoning response: The question is not about a specific method, but how they work together to improve the result of the function query_vector_database, which refers to the subject in a general way.\u001b[0m\n",
      "\u001b[34mAgent answer: general \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: GeneralRetriever\u001b[0m\n",
      "\u001b[34m\tExact match of subject: {'query_vector_database'} in the database. --> 1\u001b[0m\n",
      "\u001b[34mScore: 1 for text: \n",
      "async def query_vector_database(request: Request, db: Session = Depends(get_db)):\n",
      "    \n",
      "    import psycopg2\n",
      "    from pgvector.psycopg2 import register_vector\n",
      "    from .database.base import SQLALCHEMY_DATABASE_URL\n",
      "    import numpy as np\n",
      "    \n",
      "    body = await request.json()\n",
      "    code = body['code']\n",
      "    \n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 1 for node --> 3bce3521-3592-4e3f-9b8b-af9b587a424b: \n",
      "class NodeWithScore:\n",
      "    \n",
      "    def __init__(self, node: Node, score: float):\n",
      "        self.node = node \n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 2 for node --> 3bce3521-3592-4e3f-9b8b-af9b587a424b: \n",
      "def get_db():\n",
      "    db = SessionLocal()\n",
      "    try:\n",
      "        yield db\n",
      "    finally:\n",
      "        db.close()\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 3 for node --> 3bce3521-3592-4e3f-9b8b-af9b587a424b: \n",
      "def create_embedding(query: str):\n",
      "    query = query.replace(\"\\n\", \"\")\n",
      "    return openai_client.embeddings.create(input=[query], model='text-embedding-\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 4 for node --> 3bce3521-3592-4e3f-9b8b-af9b587a424b: \n",
      "    def return_nodes_after_apply_threshold_filter(self):\n",
      "        return self._retrieved_nodes\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 5 for node --> 3bce3521-3592-4e3f-9b8b-af9b587a424b: \n",
      "    def _check_relationships_of_retrieved_nodes(self, depth: int) -> List[str]:\n",
      "        relations = []\n",
      "        for node in self._retrieved_nodes:\n",
      "    \n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 6 for node --> 3bce3521-3592-4e3f-9b8b-af9b587a424b: \n",
      "class File(Base):\n",
      "\n",
      "    __tablename__ = \"file\"\n",
      "    id = Column(UUID(as_uuid=True), primary_key=True, index=True, default=uuid.uuid4)\n",
      "    hash = Column(\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 7 for node --> 3bce3521-3592-4e3f-9b8b-af9b587a424b: \n",
      "class Node(Base):\n",
      "\n",
      "    __tablename__ = \"node\"\n",
      "    id = Column(UUID(as_uuid=True), primary_key=True, index=True, default=uuid.uuid4)\n",
      "    node_type = Co\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 8 for node --> 3bce3521-3592-4e3f-9b8b-af9b587a424b: \n",
      "    def _check_common_parent_nodes(self) -> List[Tuple[str, int]]:\n",
      "        \n",
      "        parent_node_ids =  {}\n",
      "        file_of_node_ids = {}\n",
      "        \n",
      "     \n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 9 for node --> 3bce3521-3592-4e3f-9b8b-af9b587a424b: \n",
      "    def return_nodes_with_score_after_apply_threshold_filter(self):\n",
      "        return self._retrieved_nodes_score\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 10 for node --> 3bce3521-3592-4e3f-9b8b-af9b587a424b: \n",
      "class NodePostProccesor:\n",
      "  \n",
      "    def __init__(self, retrieved_nodes_score: List[NodeWithScore], db: Session, score_threshold: float=0.8, min_parent_nod\n",
      "\u001b[0m\n",
      "\u001b[34m\tFiltered relationships -> Before filtering: 10. After: 3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "how do the methods: _check_common_parent_nodes, _check_relationships_of_retrieved_nodes, return_nodes_after_apply_threshold_filter and return_nodes_with_score_after_apply_threshold_filter work together \n",
    "to improve the result of the function query_vector_database?\n",
    "\"\"\"\n",
    "\n",
    "answer, relationships, filterd_relationships = asyncio.run(\n",
    "    query_pipeline(agent=multi_agent, \n",
    "                   query=query, \n",
    "                   llm=llm, \n",
    "                   db=db)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "A Python expert!\n",
      "Let's break down how these methods work together to improve the result of the `query_vector_database`\n",
      "function:\n",
      "**Overview**\n",
      "The `NodePostProccesor` class is designed to process and filter nodes from a database. The four\n",
      "methods you mentioned are part of this processing pipeline.\n",
      "**Method 1: `_check_common_parent_nodes`**\n",
      "This method takes the retrieved nodes and checks for common parent nodes (methods) and files.\n",
      "It returns a list of tuples containing the parent node IDs and their frequencies.\n",
      "**Method 2: `_check_relationships_of_retrieved_nodes`**\n",
      "This method recursively explores the relationships between nodes, starting from each node in the `retrieved_nodes`\n",
      "list. For each node, it checks its relationships (i.e., child nodes) and adds them to\n",
      "a list. The recursion depth is controlled by the `depth` parameter.\n",
      "**Method 3: `return_nodes_after_apply_threshold_filter`**\n",
      "This method simply returns the filtered nodes (`_retrieved_nodes`) that passed the threshold score filter.\n",
      "**Method 4: `return_nodes_with_score_after_apply_threshold_filter`**\n",
      "This method returns the original nodes with scores (`_retrieved_nodes_score`) that passed the threshold score filter.\n",
      "This is useful for retaining the original node scores for further processing or analysis.\n",
      "**How they work together**\n",
      "Here's how these methods contribute to improving the result of `query_vector_database`:\n",
      "1. `_check_common_parent_nodes`: By identifying common parent nodes and files, you can prune the node graph\n",
      "and focus on more relevant nodes.\n",
      "2. `_check_relationships_of_retrieved_nodes`: This method recursively explores relationships between nodes, which helps to identify more connected\n",
      "nodes (e.g., methods with similar functionality).\n",
      "3. `return_nodes_after_apply_threshold_filter` and `return_nodes_with_score_after_apply_threshold_filter`: These methods filter out nodes that don't meet the threshold score,\n",
      "ensuring only relevant nodes are retained.\n",
      "By combining these methods, you can:\n",
      "* Prune the node graph to focus on more relevant nodes\n",
      "* Identify connected nodes (e.g., methods with similar functionality)\n",
      "* Retain only nodes that meet a certain threshold score\n",
      "This processing pipeline helps to improve the result of `query_vector_database` by filtering out irrelevant nodes\n",
      "and retaining only the most meaningful ones.\n"
     ]
    }
   ],
   "source": [
    "answer = format_answer(answer=answer, max_words=15)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class File(Base):\n",
      "\n",
      "    __tablename__ = \"file\"\n",
      "    id = Column(UUID(as_uuid=True), primary_key=True, index=True, default=uuid.uuid4)\n",
      "    hash = Column(String, nullable=False, index=True, unique=True)\n",
      "    path = Column(String, nullable=False, index=True, unique=True)\n",
      "    created_at = Column(DateTime, nullable=False, server_default=sqlalchemy.func.now(), onupdate=sqlalchemy.func.now())\n",
      "    updated_at = Column(DateTime, nullable=False, server_default=sqlalchemy.func.now(), onupdate=sqlalchemy.func.now())\n",
      "\n",
      "    nodes = relationship(\"Node\", back_populates=\"file\")\n",
      "\n",
      "class Node(Base):\n",
      "\n",
      "    __tablename__ = \"node\"\n",
      "    id = Column(UUID(as_uuid=True), primary_key=True, index=True, default=uuid.uuid4)\n",
      "    node_type = Column(Enum(NodeType), nullable=False)\n",
      "    file_id = Column(UUID, ForeignKey(\"file.id\", ondelete='CASCADE'), nullable=False)\n",
      "    parent_node_id = Column(UUID(as_uuid=True), ForeignKey(\"node.id\"), nullable=True)\n",
      "    text = Column(Text, nullable=False)\n",
      "    embedding_text_1536 = Column(Vector(1536))\n",
      "    hash = Column(String, nullable=False, index=True)\n",
      "    node_relationships = Column(JSONB)\n",
      "    \n",
      "    parent = relationship(\"Node\",foreign_keys=[parent_node_id],\n",
      "                          remote_side=[id],\n",
      "                          backref=backref(\"children\", cascade=\"all, delete-orphan\"))\n",
      "    \n",
      "    file = relationship(\"File\", back_populates=\"nodes\", foreign_keys=[file_id])\n",
      "    node_metadata = relationship(\"NodeMetadata\", back_populates=\"node\")\n",
      "\n",
      "class NodePostProccesor:\n",
      "  \n",
      "    def __init__(self, retrieved_nodes_score: List[NodeWithScore], db: Session, score_threshold: float=0.8, min_parent_nodes: int=2, min_file_nodes: int=2):\n",
      "        \n",
      "        self._retrieved_nodes_score = [node for node in retrieved_nodes_score if node.score > score_threshold]\n",
      "        self._retrieved_nodes = [node.node for node in self._retrieved_nodes_score]\n",
      "        \n",
      "        self._score_threshold = score_threshold\n",
      "        self._db = db \n",
      "        \n",
      "        self._retrieved_nodes_types = self._check_retrieved_nodes_type(retrieved_nodes_score)\n",
      "\n",
      "        self._min_parent_nodes = min_parent_nodes\n",
      "        self._min_file_nodes = min_file_nodes\n",
      "        \n",
      "    def return_nodes_after_apply_threshold_filter(self):\n",
      "        return self._retrieved_nodes\n",
      "    \n",
      "    def return_nodes_with_score_after_apply_threshold_filter(self):\n",
      "        return self._retrieved_nodes_score\n",
      "    \n",
      "    def _check_retrieved_nodes_type(self, nodes: List[NodeWithScore]) -> List[NodeType]:\n",
      "        _types = []\n",
      "        for node in nodes:\n",
      "            node_type: NodeType = node.node.node_type\n",
      "            _types.append(node_type)\n",
      "            \n",
      "        return _types \n",
      "    \n",
      "    def _check_common_parent_nodes(self) -> List[Tuple[str, int]]:\n",
      "        \n",
      "        parent_node_ids =  {}\n",
      "        file_of_node_ids = {}\n",
      "        \n",
      "        for node in self._retrieved_nodes_score:\n",
      "            \n",
      "            node: Node = node.node \n",
      "            file_id = node.file_id\n",
      "            \n",
      "            if node.node_type.value == NodeType.METHOD.value:\n",
      "                parent_node_id = node.parent_node_id\n",
      "                parent_node_ids[parent_node_id] = 1 if parent_node_id not in parent_node_ids else parent_node_ids[parent_node_id] + 1\n",
      "            file_of_node_ids[file_id] = 1 if file_id not in file_of_node_ids else file_of_node_ids[file_id] + 1\n",
      "        \n",
      "        return [\n",
      "            [(parent_node_id, frequency) for (parent_node_id, frequency) in parent_node_ids.items() if frequency >= self._min_parent_nodes], \n",
      "            [(file_id, frequency) for (file_id, frequency) in file_of_node_ids.items() if frequency >= self._min_file_nodes]\n",
      "        ]\n",
      "        \n",
      "    def _check_relationships_of_retrieved_nodes(self, depth: int) -> List[str]:\n",
      "        relations = []\n",
      "        for node in self._retrieved_nodes:\n",
      "            id = node.id\n",
      "            node_relationships = self._db.get(Node, id).node_relationships\n",
      "            if not node_relationships or not len(node_relationships): continue\n",
      "            for node_relationship_id, _ in node_relationships.items():\n",
      "                node_ = self._db.get(Node, node_relationship_id)\n",
      "                relations.extend(self.__retrieve_relationship_nodes(base_id=id, node=node_, depth=depth))\n",
      "                # relations.append(node_.id)\n",
      "        return relations\n",
      "\n",
      "    def __retrieve_relationship_nodes(self, base_id: str, node: Node, depth: int):\n",
      "        if base_id == str(node.id) or depth == 0: \n",
      "            return [node.id]\n",
      "        relations = []\n",
      "        node_relationships = node.node_relationships\n",
      "        if not node_relationships or not len(node_relationships):\n",
      "            return [node.id]\n",
      "        for id, _ in node_relationships.items():\n",
      "            node_ = self._db.get(Node, id)\n",
      "            relations.extend(self.__retrieve_relationship_nodes(base_id=base_id, node=node_, depth=depth-1))\n",
      "        return relations        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _, rel_nodes in filterd_relationships.items():\n",
    "    for node in rel_nodes:\n",
    "        print(node.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, File-Node-NodePostProcessor class has been used for the context as additional relationships, giving the LLM a better context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subject is the function upload_file_zip therefore the answer is simple because there is only one subject.\u001b[0m\n",
      "\u001b[34mAgent answer: simple \n",
      "\u001b[0m\n",
      "\u001b[34mAgent reasoning response: The question is regarding the function upload_file_zip itself, therefore the answer is particular\u001b[0m\n",
      "\u001b[34mAgent answer: particular \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: SimilarityRetriever\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mOriginal Query: \n",
      "How does the function upload_file_zip works?\n",
      "\u001b[0m\n",
      "\u001b[34m\tExact match of subject: upload_file_zip in the database. --> 1\u001b[0m\n",
      "\u001b[34mRelationships of node retrieve: 8\u001b[0m\n",
      "\u001b[34mScore: 1 for text: \n",
      "async def upload_file_zip(file: UploadFile = File(...), db: Session = Depends(get_db)):\n",
      "\n",
      "    extract_dir = os.environ['USER_CODE_DIRECTORY']\n",
      "    if not os.path.exists(extract_dir):\n",
      "        # shutil.rmtree(extract_dir)\n",
      "        \n",
      "        os.makedirs(extract_dir, exist_ok=True)\n",
      "\n",
      "        with open(f\"{ext\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 1 for node --> ffcb964e-0fd7-471a-9642-a3b20ad0ad4e: \n",
      "def _create_file_node(path: str, db: Session):\n",
      "    updated_files = []\n",
      "    for root, _, files in os.walk(path):\n",
      "        for file in files:\n",
      "            \n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 2 for node --> ffcb964e-0fd7-471a-9642-a3b20ad0ad4e: \n",
      "async def upload_file_zip(file: UploadFile = File(...), db: Session = Depends(get_db)):\n",
      "\n",
      "    extract_dir = os.environ['USER_CODE_DIRECTORY']\n",
      "    if no\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 3 for node --> ffcb964e-0fd7-471a-9642-a3b20ad0ad4e: \n",
      "async def upload_file_zip(file: UploadFile = File(...), db: Session = Depends(get_db)):\n",
      "\n",
      "    extract_dir = os.environ['USER_CODE_DIRECTORY']\n",
      "    if no\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 4 for node --> ffcb964e-0fd7-471a-9642-a3b20ad0ad4e: \n",
      "def get_db():\n",
      "    db = SessionLocal()\n",
      "    try:\n",
      "        yield db\n",
      "    finally:\n",
      "        db.close()\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 5 for node --> ffcb964e-0fd7-471a-9642-a3b20ad0ad4e: \n",
      "class File(Base):\n",
      "\n",
      "    __tablename__ = \"file\"\n",
      "    id = Column(UUID(as_uuid=True), primary_key=True, index=True, default=uuid.uuid4)\n",
      "    hash = Column(\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 6 for node --> ffcb964e-0fd7-471a-9642-a3b20ad0ad4e: \n",
      "async def upload_file_zip(file: UploadFile = File(...), db: Session = Depends(get_db)):\n",
      "\n",
      "    extract_dir = os.environ['USER_CODE_DIRECTORY']\n",
      "    if no\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 7 for node --> ffcb964e-0fd7-471a-9642-a3b20ad0ad4e: \n",
      "async def upload_file_zip(file: UploadFile = File(...), db: Session = Depends(get_db)):\n",
      "\n",
      "    extract_dir = os.environ['USER_CODE_DIRECTORY']\n",
      "    if no\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 8 for node --> ffcb964e-0fd7-471a-9642-a3b20ad0ad4e: \n",
      "def _create_node_relationships_file(db: Session):\n",
      "    \n",
      "    fields = ('class_name', 'function_name', 'method_name')\n",
      "    name_file = os.environ['NAMES_F\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\tFiltered relationships -> Before filtering: 8. After: 0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "How does the function upload_file_zip works?\n",
    "\"\"\"\n",
    "\n",
    "answer_without_relationships, relationships, filterd_relationships = asyncio.run(\n",
    "    query_pipeline(agent=multi_agent, \n",
    "                   query=query, \n",
    "                   llm=llm, \n",
    "                   db=db, \n",
    "                   threshold=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "I'd be happy to explain how the `upload_file_zip` function works.\n",
      "The function is designed to handle uploading a ZIP file and extracting its contents to\n",
      "a specific directory, which is stored in an environment variable called `USER_CODE_DIRECTORY`.\n",
      "Here's a step-by-step breakdown of what the function does:\n",
      "1. It checks if the specified directory exists. If it doesn't, it creates it.\n",
      "2. It writes the uploaded ZIP file to disk using the `file.read()` method and then\n",
      "extracts its contents using the `ZipFile` class from Python's standard library.\n",
      "3. After extraction, it removes the original ZIP file from disk.\n",
      "Once the contents of the ZIP file are extracted, the function does some additional processing:\n",
      "1. It finds all Python files (`*.py`) in the extracted directory and adds their paths\n",
      "to a list called `py_files`.\n",
      "2. For any other files (not `.py`), it removes them.\n",
      "3. Finally, it calls two helper functions `_create_file_node` and `_create_node_relationships_file` to perform some unknown operations\n",
      "(these functions are not defined in the provided code). These functions seem to interact with\n",
      "a database (`db`) and create nodes or relationships.\n",
      "The function returns a dictionary containing the list of extracted Python files (`py_files`).\n",
      "I hope this helps! Let me know if you have any further questions.\n"
     ]
    }
   ],
   "source": [
    "formated_answer_without_rel = format_answer(answer=answer_without_relationships, max_words=15)\n",
    "print(formated_answer_without_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAgent reasoning response: The subject is the function upload_file_zip therefore the answer is simple because there is only one subject\u001b[0m\n",
      "\u001b[34mAgent answer: simple \n",
      "\u001b[0m\n",
      "\u001b[34mAgent reasoning response: The question is regarding the function itself, therefore the answer is particular\u001b[0m\n",
      "\u001b[34mAgent answer: particular \n",
      "\u001b[0m\n",
      "\u001b[32mTool decided by the agent: SimilarityRetriever\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/Desktop/Project-Ideas/python-gpt/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mOriginal Query: \n",
      "How does the function upload_file_zip works?\n",
      "\u001b[0m\n",
      "\u001b[34m\tExact match of subject: upload_file_zip in the database. --> 1\u001b[0m\n",
      "\u001b[34mRelationships of node retrieve: 8\u001b[0m\n",
      "\u001b[34mScore: 1 for text: \n",
      "async def upload_file_zip(file: UploadFile = File(...), db: Session = Depends(get_db)):\n",
      "\n",
      "    extract_dir = os.environ['USER_CODE_DIRECTORY']\n",
      "    if not os.path.exists(extract_dir):\n",
      "        # shutil.rmtree(extract_dir)\n",
      "        \n",
      "        os.makedirs(extract_dir, exist_ok=True)\n",
      "\n",
      "        with open(f\"{ext\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 1 for node --> ffcb964e-0fd7-471a-9642-a3b20ad0ad4e: \n",
      "def _create_file_node(path: str, db: Session):\n",
      "    updated_files = []\n",
      "    for root, _, files in os.walk(path):\n",
      "        for file in files:\n",
      "            \n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 2 for node --> ffcb964e-0fd7-471a-9642-a3b20ad0ad4e: \n",
      "async def upload_file_zip(file: UploadFile = File(...), db: Session = Depends(get_db)):\n",
      "\n",
      "    extract_dir = os.environ['USER_CODE_DIRECTORY']\n",
      "    if no\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 3 for node --> ffcb964e-0fd7-471a-9642-a3b20ad0ad4e: \n",
      "async def upload_file_zip(file: UploadFile = File(...), db: Session = Depends(get_db)):\n",
      "\n",
      "    extract_dir = os.environ['USER_CODE_DIRECTORY']\n",
      "    if no\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 4 for node --> ffcb964e-0fd7-471a-9642-a3b20ad0ad4e: \n",
      "def get_db():\n",
      "    db = SessionLocal()\n",
      "    try:\n",
      "        yield db\n",
      "    finally:\n",
      "        db.close()\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 5 for node --> ffcb964e-0fd7-471a-9642-a3b20ad0ad4e: \n",
      "class File(Base):\n",
      "\n",
      "    __tablename__ = \"file\"\n",
      "    id = Column(UUID(as_uuid=True), primary_key=True, index=True, default=uuid.uuid4)\n",
      "    hash = Column(\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 6 for node --> ffcb964e-0fd7-471a-9642-a3b20ad0ad4e: \n",
      "async def upload_file_zip(file: UploadFile = File(...), db: Session = Depends(get_db)):\n",
      "\n",
      "    extract_dir = os.environ['USER_CODE_DIRECTORY']\n",
      "    if no\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 7 for node --> ffcb964e-0fd7-471a-9642-a3b20ad0ad4e: \n",
      "async def upload_file_zip(file: UploadFile = File(...), db: Session = Depends(get_db)):\n",
      "\n",
      "    extract_dir = os.environ['USER_CODE_DIRECTORY']\n",
      "    if no\n",
      "\u001b[0m\n",
      "\u001b[34m\tRelationship 8 for node --> ffcb964e-0fd7-471a-9642-a3b20ad0ad4e: \n",
      "def _create_node_relationships_file(db: Session):\n",
      "    \n",
      "    fields = ('class_name', 'function_name', 'method_name')\n",
      "    name_file = os.environ['NAMES_F\n",
      "\u001b[0m\n",
      "\u001b[34m\tFiltered relationships -> Before filtering: 8. After: 3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "How does the function upload_file_zip works?\n",
    "\"\"\"\n",
    "\n",
    "answer_with_relationships, relationships, filterd_relationships = asyncio.run(\n",
    "    query_pipeline(agent=multi_agent, \n",
    "                   query=query, \n",
    "                   llm=llm, \n",
    "                   db=db, \n",
    "                   threshold=0.3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Let's dive into the code and explain how `upload_file_zip` works.\n",
      "The `upload_file_zip` function takes two parameters:\n",
      "- `file`: This is an UploadFile object, which seems to be a file uploaded through\n",
      "some kind of API or form. It has a `filename` attribute.\n",
      "- `db`: This is a database session (more on this later). The `Depends(get_db)` part suggests\n",
      "that this function relies on the result of calling `get_db()`.\n",
      "Here's what the function does:\n",
      "1. It extracts an environment variable called `USER_CODE_DIRECTORY`. If this directory doesn't exist, it creates\n",
      "it.\n",
      "2. It writes the uploaded file to a local file in this directory.\n",
      "3. It then extracts a ZIP archive from the uploaded file (assuming it's a ZIP\n",
      "file) and places its contents into the same directory.\n",
      "4. Finally, it removes the original uploaded ZIP file and some other files/directories within that\n",
      "directory.\n",
      "Let me break down what's happening here:\n",
      "- `os.environ['USER_CODE_DIRECTORY']`: This line is accessing an environment variable (a string set by the user\n",
      "or another program) named `USER_CODE_DIRECTORY`. It's likely being used as a temporary storage area for\n",
      "files.\n",
      "- `if not os.path.exists(directory): os.makedirs(directory)`: If this directory doesn't exist, Python creates it. The `os`\n",
      "module provides a way to work with the operating system and file systems.\n",
      "- `with open(file_path, 'wb') as f: f.write(file_bytes)`: This is writing the uploaded file (which seems\n",
      "to be a ZIP archive) to a local file in the temporary directory.\n",
      "- `zipfile.ZipFile.open(file_path, mode='w')`: It's opening this ZIP file and extracting its contents into the same\n",
      "directory. `zipfile` is another Python module for working with ZIP files.\n",
      "The last part of the function (`os.remove()` calls) seems to be removing some temporary files\n",
      "and directories that were created during the process.\n"
     ]
    }
   ],
   "source": [
    "formated_answer_with_rel = format_answer(answer=answer_with_relationships, \n",
    "                                         max_words=15)\n",
    "print(formated_answer_with_rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the LLM has probably run out of context so the quality of the answer is lower. That is why is so important to correctly filter the relationships we want to use. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
